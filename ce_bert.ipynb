{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import nltk\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "import numpy as np\n",
    "tokenizer = RegexpTokenizer(r'\\w+')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer, BertModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer_bert = BertTokenizer.from_pretrained('bert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model= BertModel.from_pretrained(\"bert-base-uncased\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cos_sim(vector_a, vector_b):\n",
    "        vector_a = np.mat(vector_a)\n",
    "        vector_b = np.mat(vector_b)\n",
    "        num = float(vector_a * vector_b.T)\n",
    "        denom = np.linalg.norm(vector_a) * np.linalg.norm(vector_b)\n",
    "        sim = num / denom\n",
    "        print(\"cos\",sim)\n",
    "        return sim\n",
    "        \n",
    "def cac_bert_sim(refs, cand):\n",
    "    refs = [\" \".join(ref) for ref in refs]\n",
    "    cand = \" \".join(cand[1:]).lower()\n",
    "    sims = 0\n",
    "    for i in range(len(refs)):\n",
    "        ref = refs[i]\n",
    "        encoded_input_ref = tokenizer_bert(ref, return_tensors='pt')\n",
    "        encoded_input_cand = tokenizer_bert(cand, return_tensors='pt')\n",
    "        output_ref = model(**encoded_input_ref)[1][0].detach().numpy()\n",
    "        output_cand = model(**encoded_input_cand)[1][0].detach().numpy()\n",
    "        sims+=cos_sim(output_ref, output_cand)\n",
    "    print(sims/len(refs))\n",
    "    return sims/len(refs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cac_avg(l):\n",
    "    s = 0\n",
    "    for i in l:\n",
    "        s+=float(i)\n",
    "    return s/len(l)\n",
    "    \n",
    "def cal_bert(references, candidate):\n",
    "    references = [\" \".join(tokenizer.tokenize(i)) for i in references]\n",
    "    candidate = \" \".join(tokenizer.tokenize(candidate))\n",
    "    refs = []\n",
    "    for ref in references:\n",
    "        t = []\n",
    "        sents  = nltk.sent_tokenize(ref)\n",
    "        words = []\n",
    "        for sent in sents:\n",
    "            words.extend(nltk.word_tokenize(sent))\n",
    "        refs.append(words)\n",
    "    sents = nltk.sent_tokenize(candidate)\n",
    "    cands = []\n",
    "    for sent in sents:\n",
    "        cands.extend(nltk.word_tokenize(sent))\n",
    "    #import pdb;pdb.set_trace()\n",
    "    score = cac_bert_sim(refs, cands)\n",
    "    return score\n",
    "import spacy\n",
    "nlp =spacy.load('en_core_web_sm')\n",
    "def cut(s):\n",
    "    doc = nlp(s)\n",
    "    tokens = [i.text for i in doc]\n",
    "    return \" \".join(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "refs = []\n",
    "with open(\"./references/CE/1.CE ref.txt\", encoding=\"utf8\") as f:\n",
    "    refs.append(f.readlines())\n",
    "with open(\"./references/CE/2.CE ref.txt\", encoding=\"utf8\") as f:\n",
    "    refs.append(f.readlines())\n",
    "with open(\"./references/CE/3.CE ref.txt\", encoding=\"utf8\") as f:\n",
    "    refs.append(f.readlines())\n",
    "with open(\"./references/CE/4.CE ref.txt\", encoding=\"utf8\") as f:\n",
    "    refs.append(f.readlines())\n",
    "\n",
    "p_refs = []\n",
    "n=0\n",
    "for ref in refs:\n",
    "    t = []\n",
    "    n+=1\n",
    "    for s in ref:\n",
    "        if len(s)>5:\n",
    "            a=s[s.index(\".\")+1:].strip().lower()\n",
    "            t.append(cut(a))\n",
    "    p_refs.append(t)\n",
    "refs = p_refs\n",
    "   \n",
    "file_path = \"./C-E transcripts-sentence-txt/\"\n",
    "\n",
    "files = []\n",
    "for i,j,k in os.walk(file_path):\n",
    "    files.extend(k)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_dict = {}\n",
    "for fn in files:\n",
    "    with open(file_path+fn, \"r\", encoding=\"utf8\") as f:\n",
    "        print(fn)\n",
    "        pgs = f.readlines()\n",
    "        key = fn.split(\".\")[0]\n",
    "        score_dict[key] = {\"bert_val\":[],\"avg_bert\":0}           \n",
    "        for i in range(len(pgs)):\n",
    "            p_refs =[] \n",
    "            for j in range(len(refs)):             \n",
    "                p_refs.append(refs[j][i])\n",
    "            bert_scores = cal_bert(p_refs, pgs[i])\n",
    "            score_dict[key][\"bert_val\"].append(bert_scores)\n",
    "        score_dict[key][\"avg_bert\"] = cac_avg(score_dict[key][\"bert_val\"])\n",
    "import json\n",
    "with open(\"ce_bert_score.json\", \"w\", encoding=\"utf8\") as f:\n",
    "    json.dump(score_dict, f, indent=4,sort_keys=True)\n",
    "print(score_dict)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"ce_bert_score.json\", encoding=\"utf8\") as f:\n",
    "    r = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k in r:\n",
    "    print(str(r[k][\"avg_bert\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
